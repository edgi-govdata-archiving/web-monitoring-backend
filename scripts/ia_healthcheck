#!/usr/bin/env python

from datetime import datetime, timedelta
import random
import sys
from web_monitoring import db
from web_monitoring import internetarchive


MAX_CAPTURE_AGE = timedelta(hours=72)
LINKS_TO_CHECK = 5


def query_webmondb():
    """
    Query the web monitoring SCANNER API to get random links from the database

    Returns
    -------
    list of string
    """
    try:
        client = db.Client.from_env()
    except db.MissingCredentials as error:
        print(error, file=sys.stderr)
        return []
    else:
        page = client.list_pages(chunk=1, chunk_size=1)
        url_count = page['meta']['total_results']
        return ([get_links(client, number)
            for number in random.sample(range(url_count), LINKS_TO_CHECK)])

def get_links(client, index):
    return client.list_pages(chunk=index, chunk_size=1)['data'][0]['url']

def query_wayback_cdx(url):
    """
    Query Wayback Machine using CDX API
    Get a list of versions of a url, and check for ValueError

    Parameters
    ----------
    url : string

    Returns
    -------
    list of JSON
    """
    try:
        versions = internetarchive.list_versions(url,
            from_date=datetime.now() - MAX_CAPTURE_AGE)
        next(versions)
    except ValueError as error:
        return False
    else:
        return True


def output_file(responses):
    """
    Write Output to a Text file

    Parameters
    ----------
    responses: list of string
    """
    healthy_links = 0
    unhealthy_links = 0

    if not responses:
        print('No links were returned.')
    else:
        for (url, status) in responses:
            print(str(status) + ': ' + str(url)+'\n\n\n')
            if status:
                healthy_links += 1
            else:
                unhealthy_links += 1
        print('Found: {} Healthy Links and {} Unhealthy Links.'
.format(healthy_links, unhealthy_links))


def output_sentry():
    """
    Send Output to sentry
    """
    raise NotImplementedError

# Get the random list of links from the Web Monitoring DB
# Get the responses of the links from the Wayback URL
# Check to see if the responses are within the time limit and write the output


if __name__ == "__main__":

    links = query_webmondb()
    responses = [(url, query_wayback_cdx(url)) for url in links if url]
    output_file(responses)
